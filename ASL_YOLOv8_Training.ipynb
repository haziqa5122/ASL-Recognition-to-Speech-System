{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj4SH3ipaU-k",
        "outputId": "3acbd071-1c0e-4a8b-ecb6-0a2c3ce68d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.54-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.54-py3-none-any.whl (903 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m903.1/903.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.54 ultralytics-thop-2.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "***Import Necessary Libraries***"
      ],
      "metadata": {
        "id": "UpkGWltfcv6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import yaml\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "_0yE8ZPjcoKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load and Explore the Dataset***"
      ],
      "metadata": {
        "id": "KAE1KEXvc6pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yaml(dataset_path: str, yaml_filename: str) -> dict:\n",
        "    \"\"\"Loads data from a YAML file.\n",
        "\n",
        "    Args:\n",
        "      dataset_path: The path to the dataset directory.\n",
        "      yaml_filename: The name of the YAML file.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary containing the loaded YAML data.\n",
        "    \"\"\"\n",
        "    yaml_file_path = os.path.join(dataset_path, yaml_filename)\n",
        "\n",
        "    try:\n",
        "        with open(yaml_file_path, 'r') as file:\n",
        "            yaml_content = yaml.safe_load(file)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"YAML file not found: {yaml_file_path}\")\n",
        "    except yaml.YAMLError as e:\n",
        "        raise ValueError(f\"Error parsing YAML file: {e}\")\n",
        "\n",
        "    return yaml_content\n",
        "\n",
        "# Define the dataset path and YAML filename\n",
        "dataset_path = '/aug-asl-dataset'\n",
        "yaml_filename = 'data.yaml'\n",
        "\n",
        "# Load the YAML file\n",
        "yaml_content = load_yaml(dataset_path, yaml_filename)\n",
        "print(yaml.dump(yaml_content, default_flow_style=False))"
      ],
      "metadata": {
        "id": "BtcT_j9uc4_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Analyze the Images***"
      ],
      "metadata": {
        "id": "W-zGDaffdCuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_images(dataset_path: str, data_type: str) -> tuple:\n",
        "    \"\"\"Analyzes image sizes and counts in a given dataset directory.\n",
        "\n",
        "    Args:\n",
        "      dataset_path: The path to the dataset directory.\n",
        "      data_type: The type of data ('train' or 'valid').\n",
        "\n",
        "    Returns:\n",
        "      A tuple containing the number of images and a set of unique image sizes.\n",
        "    \"\"\"\n",
        "\n",
        "    images_path = os.path.join(dataset_path, data_type, 'images')\n",
        "    num_images = 0\n",
        "    image_sizes = set()\n",
        "\n",
        "    try:\n",
        "        for filename in os.listdir(images_path):\n",
        "            if filename.endswith('.jpg'):\n",
        "                num_images += 1\n",
        "                image_path = os.path.join(images_path, filename)\n",
        "                with Image.open(image_path) as img:\n",
        "                    image_sizes.add(img.size)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Image directory not found: {images_path}\")\n",
        "\n",
        "    return num_images, image_sizes\n",
        "\n",
        "# Analyze the training images\n",
        "num_train_images, train_image_sizes = analyze_images(dataset_path, 'train')\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "if len(train_image_sizes) == 1:\n",
        "    print(f\"All training images have the same size: {train_image_sizes.pop()}\")\n",
        "else:\n",
        "    print(\"Training images have varying sizes.\")\n",
        "\n",
        "# Analyze the validation images\n",
        "num_valid_images, valid_image_sizes = analyze_images(dataset_path, 'valid')\n",
        "print(f\"Number of validation images: {num_valid_images}\")\n",
        "if len(valid_image_sizes) == 1:\n",
        "    print(f\"All validation images have the same size: {valid_image_sizes.pop()}\")\n",
        "else:\n",
        "    print(\"Validation images have varying sizes.\")"
      ],
      "metadata": {
        "id": "QCGOo07odGle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Visualize Sample Images***"
      ],
      "metadata": {
        "id": "rjpucaDDdKnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_sample_images(images_path: str, num_samples: int = 8, grid_shape: tuple = (2, 4)) -> None:\n",
        "    \"\"\"Displays a grid of sample images from a directory.\n",
        "\n",
        "    Args:\n",
        "      images_path: The path to the directory containing images.\n",
        "      num_samples: The number of sample images to display.\n",
        "      grid_shape: The shape of the grid to display the images in (rows, columns).\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        image_files = [file for file in os.listdir(images_path) if file.endswith('.jpg')]\n",
        "\n",
        "        if len(image_files) < num_samples:\n",
        "            raise ValueError(f\"Not enough images in the directory to display {num_samples} samples.\")\n",
        "\n",
        "        # Select images at equal intervals\n",
        "        num_images = len(image_files)\n",
        "        selected_images = [image_files[i] for i in range(0, num_images, num_images // num_samples)]\n",
        "\n",
        "        # Create a subplot\n",
        "        fig, axes = plt.subplots(*grid_shape, figsize=(20, 11))\n",
        "\n",
        "        # Display each of the selected images\n",
        "        for ax, img_file in zip(axes.ravel(), selected_images):\n",
        "            img_path = os.path.join(images_path, img_file)\n",
        "            image = Image.open(img_path)\n",
        "            ax.imshow(image)\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.suptitle('Sample Images from Training Dataset', fontsize=20)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Image directory not found: {images_path}\")\n",
        "\n",
        "# Display sample images from the training set\n",
        "train_images_path = os.path.join(dataset_path, 'train', 'images')\n",
        "display_sample_images(train_images_path)"
      ],
      "metadata": {
        "id": "PoIP0CJXdMi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Train the YOLOv8 Model***"
      ],
      "metadata": {
        "id": "VlWOKgxhdQp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_yolo_model(\n",
        "    yaml_file_path: str,\n",
        "    epochs: int = 20,\n",
        "    imgsz: int = 640,\n",
        "    device: int = 0,\n",
        "    patience: int = 50,\n",
        "    batch: int = 32,\n",
        "    optimizer: str = 'auto',\n",
        "    lr0: float = 0.0001,\n",
        "    lrf: float = 0.1,\n",
        "    dropout: float = 0.1,\n",
        "    seed: int = 0\n",
        ") -> YOLO:\n",
        "    \"\"\"Trains a YOLO model on a custom dataset.\n",
        "\n",
        "    Args:\n",
        "      yaml_file_path: Path to the dataset configuration file (data.yaml).\n",
        "      epochs: Number of epochs to train for.\n",
        "      imgsz: Size of input images as integer.\n",
        "      device: Device to run on (i.e., cuda device=0).\n",
        "      patience: Epochs to wait for no observable improvement for early stopping.\n",
        "      batch: Number of images per batch.\n",
        "      optimizer: Optimizer to use (choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]).\n",
        "      lr0: Initial learning rate.\n",
        "      lrf: Final learning rate (lr0 * lrf).\n",
        "      dropout: Use dropout regularization.\n",
        "      seed: Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        The trained YOLO model.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        model = YOLO('yolov8m.pt')  # Load a pretrained YOLO model\n",
        "        results = model.train(\n",
        "            data=yaml_file_path,\n",
        "            epochs=epochs,\n",
        "            imgsz=imgsz,\n",
        "            device=device,\n",
        "            patience=patience,\n",
        "            batch=batch,\n",
        "            optimizer=optimizer,\n",
        "            lr0=lr0,\n",
        "            lrf=lrf,\n",
        "            dropout=dropout,\n",
        "            seed=seed\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during training: {e}\")\n",
        "        return None\n",
        "\n",
        "# Train the model\n",
        "yaml_file_path = os.path.join(dataset_path, 'data.yaml')\n",
        "trained_model = train_yolo_model(yaml_file_path)"
      ],
      "metadata": {
        "id": "e7tjq1NgdVVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Validate the Model and Display Inferences***"
      ],
      "metadata": {
        "id": "kTz9bG0kdlYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def display_training_results(folder_path):\n",
        "  \"\"\"\n",
        "  Displays the training result images (plots and visualizations)\n",
        "  from a specified folder.\n",
        "\n",
        "  Args:\n",
        "    folder_path (str): The path to the folder containing the result images.\n",
        "  \"\"\"\n",
        "\n",
        "  # Get a list of all files in the folder\n",
        "  all_files = os.listdir(folder_path)\n",
        "\n",
        "  # Filter for image files (you can add more extensions if needed)\n",
        "  image_files = [\n",
        "      f for f in all_files\n",
        "      if f.endswith(('.png', '.jpg', '.jpeg'))\n",
        "  ]\n",
        "\n",
        "  # Calculate the number of rows and columns for subplots\n",
        "  num_images = len(image_files)\n",
        "  num_cols = 4  # You can adjust this\n",
        "  num_rows = (num_images + num_cols - 1) // num_cols\n",
        "\n",
        "  # Create a figure and axes for the subplots\n",
        "  fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 20))\n",
        "  fig.suptitle('YOLOv8 Training Results', fontsize=16)\n",
        "\n",
        "  # Flatten the axes array for easier iteration\n",
        "  axes = axes.flatten()\n",
        "\n",
        "  for i, img_name in enumerate(image_files):\n",
        "    img_path = os.path.join(folder_path, img_name)\n",
        "\n",
        "    try:\n",
        "      # Load the image\n",
        "      img = mpimg.imread(img_path)\n",
        "\n",
        "      # Display the image on the corresponding subplot\n",
        "      axes[i].imshow(img)\n",
        "      axes[i].set_title(img_name.split('.')[0])\n",
        "      axes[i].axis('off')\n",
        "\n",
        "    except FileNotFoundError:\n",
        "      print(f\"Image not found: {img_path}\")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "  # Hide any empty subplots\n",
        "  for j in range(i + 1, len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "  # Adjust layout for better spacing\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Example usage:\n",
        "folder_path = 'current-dir/runs/detect/train'\n",
        "display_training_results(folder_path)"
      ],
      "metadata": {
        "id": "_QZcSHx0dneT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_validation_inferences(model: YOLO, dataset_path: str, num_samples: int = 9) -> None:\n",
        "    \"\"\"Displays inferences on sample images from the validation set.\n",
        "\n",
        "    Args:\n",
        "        model: The trained YOLO model.\n",
        "        dataset_path: The path to the dataset directory.\n",
        "        num_samples: The number of sample images to display.\n",
        "    \"\"\"\n",
        "\n",
        "    if model is None:\n",
        "        print(\"Model not trained. Skipping validation inference.\")\n",
        "        return\n",
        "\n",
        "    valid_images_path = os.path.join(dataset_path, 'valid', 'images')\n",
        "\n",
        "    try:\n",
        "        # List all jpg images in the directory\n",
        "        image_files = [file for file in os.listdir(valid_images_path) if file.endswith('.jpg')]\n",
        "\n",
        "        if len(image_files) < num_samples:\n",
        "            raise ValueError(f\"Not enough images in the directory to display {num_samples} samples.\")\n",
        "\n",
        "        # Select images at equal intervals\n",
        "        num_images = len(image_files)\n",
        "        selected_images = [image_files[i] for i in range(0, num_images, num_images // num_samples)]\n",
        "\n",
        "        # Initialize the subplot\n",
        "        fig, axes = plt.subplots(3, 3, figsize=(20, 21))\n",
        "        fig.suptitle('Validation Set Inferences', fontsize=24)\n",
        "\n",
        "        # Perform inference on each selected image and display it\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            image_path = os.path.join(valid_images_path, selected_images[i])\n",
        "            results = model.predict(source=image_path, imgsz=640, conf=0.5)\n",
        "            annotated_image = results[0].plot(line_width=1)\n",
        "            annotated_image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "            ax.imshow(annotated_image_rgb)\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Image directory not found: {valid_images_path}\")\n",
        "\n",
        "# Display inferences on validation set\n",
        "display_validation_inferences(trained_model, dataset_path)"
      ],
      "metadata": {
        "id": "JNRI2XzcdtlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_sample_inference(model: YOLO, sample_image_path: str) -> None:\n",
        "    \"\"\"Displays the inference on a single sample image.\n",
        "\n",
        "    Args:\n",
        "        model: The trained YOLO model.\n",
        "        sample_image_path: The path to the sample image.\n",
        "    \"\"\"\n",
        "\n",
        "    if model is None:\n",
        "        print(\"Model not trained. Skipping sample inference.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Perform inference\n",
        "        results = model.predict(source=sample_image_path, imgsz=640, conf=0.7)\n",
        "\n",
        "        # Annotate and convert image to numpy array\n",
        "        sample_image = results[0].plot(line_width=2)\n",
        "\n",
        "        # Convert the color of the image from BGR to RGB\n",
        "        sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Display annotated image\n",
        "        plt.figure(figsize=(20,15))\n",
        "        plt.imshow(sample_image)\n",
        "        plt.title('Detected Objects in Sample Image by the Fine-tuned YOLOv8 Model', fontsize=20)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during sample inference: {e}\")\n",
        "\n",
        "\n",
        "# Path to a sample image file for inference\n",
        "sample_image_path = '/asl-dataset/test/images/I17.jpg'\n",
        "display_sample_inference(trained_model, sample_image_path)"
      ],
      "metadata": {
        "id": "WDKELPCvduYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHHHtSEp7JNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FN2LV8A584TQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}